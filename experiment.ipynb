{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG1 = \"en\"\n",
    "LANG2 = \"nl\"\n",
    "EXAMPLE_TOKEN_LEN = 100\n",
    "MODEL_SIZE1 = \"125M\"\n",
    "MODEL_SIZE2 = \"1.3B\"\n",
    "MODEL_SIZE3 = \"2.7B\"\n",
    "MODEL_SIZE4 = \"6B\"\n",
    "\n",
    "DATASET_DIR = \"EMEA\"\n",
    "DATASET_NAME = \"europarl-v7.nl-en\"\n",
    "SOURCE_DIR = \"./test\"\n",
    "\n",
    "# Create config file\n",
    "config = {\n",
    "    \"dataset_dir\": \"test\",\n",
    "    \"dataset_name\": \"EMEA-c\",\n",
    "    \"source_dir\": SOURCE_DIR,\n",
    "    \"example_token_len\": EXAMPLE_TOKEN_LEN,\n",
    "    \"root_dir\": \"test\",\n",
    "    \"experiment_name\": \"test1\",\n",
    "    \"model_name\": \"gpt2\",\n",
    "    \"num_trials\": 1,\n",
    "    \"language\": \"en\",\n",
    "    \"split\": \"train\",\n",
    "    \"suffix_len\": 50,\n",
    "    \"prefix_len\": 50,\n",
    "    \"example_token_len\": 100,\n",
    "    \"preprefix_len\": 0,\n",
    "    \"source_file\": \"train_dataset.npy\",\n",
    "    \"batch_size\": 64,\n",
    "    \"model\": \"EleutherAI/gpt-neo-2.7B\",\n",
    "    \"train_file\": \"test/100/train-en.txt\",\n",
    "    \"validation_file\": \"test/100/validation-en.txt\",\n",
    "    \"validation_split_percentage\": 0.1,\n",
    "    \"seed\": 42,\n",
    "    \"num_trial\": 50,\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "import json\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-27 13:16:26,868 - INFO - Parsing arguments...\n",
      "Parsing arguments...\n",
      "2024-06-27 13:16:26,869 - INFO - Loading tokenizer...\n",
      "Loading tokenizer...\n",
      "2024-06-27 13:16:27,112 - INFO - ==== Starting data preprocessing script ====\n",
      "==== Starting data preprocessing script ====\n",
      "2024-06-27 13:16:27,112 - INFO - This may take a while depending on the size of the dataset...\n",
      "This may take a while depending on the size of the dataset...\n",
      "2024-06-27 13:16:27,112 - INFO - Counting tokens for en...\n",
      "Counting tokens for en...\n",
      "Generating byte offset dataset from file:  test/EMEA.en\n",
      "2024-06-27 13:16:46,824 - INFO - Number of samples >= 100 tokens in ./test/test/csv/100/EMEA.en.csv: 2848\n",
      "Number of samples >= 100 tokens in ./test/test/csv/100/EMEA.en.csv: 2848\n",
      "2024-06-27 13:16:46,824 - INFO - Counting tokens for nl...\n",
      "Counting tokens for nl...\n",
      "Generating byte offset dataset from file:  test/EMEA.nl\n",
      "2024-06-27 13:17:13,646 - INFO - Number of samples >= 100 tokens in ./test/test/csv/100/EMEA.nl.csv: 17156\n",
      "Number of samples >= 100 tokens in ./test/test/csv/100/EMEA.nl.csv: 17156\n",
      "2024-06-27 13:17:13,646 - INFO - Filtering sentences that are >= 100 tokens to ./test/test/csv/100/EMEA.en.jsonl...\n",
      "Filtering sentences that are >= 100 tokens to ./test/test/csv/100/EMEA.en.jsonl...\n",
      "2024-06-27 13:17:13,806 - INFO - Concatening remaining sentences to ./test/test/csv/100/EMEA.en.jsonl\n",
      "Concatening remaining sentences to ./test/test/csv/100/EMEA.en.jsonl\n",
      "2024-06-27 13:17:14,440 - INFO - Concatenated sentences in en to reach 31241 samples >= 100 tokens\n",
      "Concatenated sentences in en to reach 31241 samples >= 100 tokens\n",
      "2024-06-27 13:17:14,440 - INFO - Generating concatenated .txt version of original dataset for both languages...\n",
      "Generating concatenated .txt version of original dataset for both languages...\n",
      "2024-06-27 13:17:14,951 - INFO - ==== Data preprocessing complete ====\n",
      "==== Data preprocessing complete ====\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Preprocess the data \n",
    "\n",
    "# increase number of usable sentences\n",
    "# runs for both languages\n",
    "!python preprocessing.py --config_file config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-27 13:18:15,796 - INFO - Parsing arguments...\n",
      "Parsing arguments...\n",
      "2024-06-27 13:18:15,796 - INFO - Loading tokenizer...\n",
      "Loading tokenizer...\n",
      "2024-06-27 13:18:16,088 - INFO - ==== Sarting data processing script ====\n",
      "==== Sarting data processing script ====\n",
      "2024-06-27 13:18:16,088 - INFO - This may take a while depending on the size of the dataset...\n",
      "This may take a while depending on the size of the dataset...\n",
      "2024-06-27 13:18:16,088 - INFO - Counting tokens for en...\n",
      "Counting tokens for en...\n",
      "Generating byte offset dataset from file:  test/100/EMEA-c.en\n",
      "2024-06-27 13:18:29,580 - INFO - Number of samples >= 100 tokens in ./test/test/csv/100/EMEA-c.en.csv: 31176\n",
      "Number of samples >= 100 tokens in ./test/test/csv/100/EMEA-c.en.csv: 31176\n",
      "2024-06-27 13:18:29,580 - INFO - Filtering sentences for en...\n",
      "Filtering sentences for en...\n",
      "2024-06-27 13:18:29,625 - INFO - Generating JSONL for en...\n",
      "Generating JSONL for en...\n",
      "2024-06-27 13:18:29,989 - INFO - Counting tokens for nl...\n",
      "Counting tokens for nl...\n",
      "Generating byte offset dataset from file:  test/100/EMEA-c.nl\n",
      "2024-06-27 13:18:49,983 - INFO - Number of samples >= 100 tokens in ./test/test/csv/100/EMEA-c.nl.csv: 31480\n",
      "Number of samples >= 100 tokens in ./test/test/csv/100/EMEA-c.nl.csv: 31480\n",
      "2024-06-27 13:18:49,983 - INFO - Filtering sentences for nl...\n",
      "Filtering sentences for nl...\n",
      "2024-06-27 13:18:50,028 - INFO - Generating JSONL for nl...\n",
      "Generating JSONL for nl...\n",
      "Number of exids in file 1: %s 31176\n",
      "Number of exids in file 2: %s 31480\n",
      "Number of common exids found %s 30611\n",
      "2024-06-27 13:18:50,488 - INFO - Common exids have been written to ./test/test/csv/100/common_exids-100.csv\n",
      "Common exids have been written to ./test/test/csv/100/common_exids-100.csv\n",
      "2024-06-27 13:18:50,492 - INFO - 30611 common example IDs found\n",
      "30611 common example IDs found\n",
      "Truncating sentences in file:  test/100/EMEA-c.en.jsonl  to  100  tokens\n",
      "Truncated  30611  sentences to  test/100/EMEA-c-100.en.jsonl\n",
      "Done!\n",
      "Truncating sentences in file:  test/100/EMEA-c.nl.jsonl  to  100  tokens\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Truncated  30611  sentences to  test/100/EMEA-c-100.nl.jsonl\n",
      "Done!\n",
      "2024-06-27 13:19:36,268 - INFO - ==== Data processing script completed ====\n",
      "==== Data processing script completed ====\n"
     ]
    }
   ],
   "source": [
    "# Step 2. Process the data to correct format\n",
    "\n",
    "# NOTE: change dataset name to name + \"-c\" in running this right after preprocessing!!!\n",
    "# gets dataset in the correct format for the experiment\n",
    "!python process_data.py --config_file config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Shrink the dataset to a smaller size\n",
    "def shrink_datasets(path1, path2, size):\n",
    "    with open(path1, \"r\") as f:\n",
    "        data1 = f.readlines()\n",
    "    with open(path2, \"r\") as f:\n",
    "        data2 = f.readlines()\n",
    "\n",
    "    num_indices = int(len(data1))\n",
    "    indices = np.random.choice(num_indices, size, replace=False)\n",
    "\n",
    "    new_data1 = [data1[i] for i in indices]\n",
    "    new_data2 = [data2[i] for i in indices]\n",
    "\n",
    "    with open(path1, \"w\") as f:\n",
    "        f.writelines(new_data1)\n",
    "    with open(path2, \"w\") as f:\n",
    "        f.writelines(new_data2)\n",
    "\n",
    "\n",
    "size = 11000\n",
    "\n",
    "path1 = os.path.join(\n",
    "    DATASET_DIR, str(EXAMPLE_TOKEN_LEN), f\"{DATASET_NAME}-{EXAMPLE_TOKEN_LEN}.{LANG1}\"\n",
    ")\n",
    "path2 = os.path.join(\n",
    "    DATASET_DIR, str(EXAMPLE_TOKEN_LEN), f\"{DATASET_NAME}-{EXAMPLE_TOKEN_LEN}.{LANG2}\"\n",
    ")\n",
    "shrink_datasets(path1, path2, size)\n",
    "\n",
    "path1 = os.path.join(\n",
    "    DATASET_DIR,\n",
    "    str(EXAMPLE_TOKEN_LEN),\n",
    "    f\"{DATASET_NAME}-{EXAMPLE_TOKEN_LEN}.{LANG1}.jsonl\",\n",
    ")\n",
    "path2 = os.path.join(\n",
    "    DATASET_DIR,\n",
    "    str(EXAMPLE_TOKEN_LEN),\n",
    "    f\"{DATASET_NAME}-{EXAMPLE_TOKEN_LEN}.{LANG2}.jsonl\",\n",
    ")\n",
    "shrink_datasets(path1, path2, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m dir3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp-configs/EMEA/200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m dir4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp-configs/EMEA/250\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mupdate_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m update_trials(dir2)\n\u001b[1;32m     31\u001b[0m update_trials(dir3)\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mupdate_trials\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_trials\u001b[39m(directory):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(directory):\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     15\u001b[0m             filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def update_batch_size(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\") as json_file:\n",
    "                data = json.load(json_file)\n",
    "            if \"batch_size\" in data:\n",
    "                data[\"batch_size\"] = 64\n",
    "                with open(filepath, \"w\") as json_file:\n",
    "                    json.dump(data, json_file, indent=4)\n",
    "\n",
    "\n",
    "def update_trials(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\") as json_file:\n",
    "                data = json.load(json_file)\n",
    "            if \"num_trials\" in data:\n",
    "                data[\"num_trials\"] = 50\n",
    "                with open(filepath, \"w\") as json_file:\n",
    "                    json.dump(data, json_file, indent=4)\n",
    "\n",
    "\n",
    "dir = \"exp-configs/EMEA/100\"\n",
    "dir2 = \"exp-configs/EMEA/150\"\n",
    "dir3 = \"exp-configs/EMEA/200\"\n",
    "dir4 = \"exp-configs/EMEA/250\"\n",
    "\n",
    "\n",
    "update_trials(dir)\n",
    "update_trials(dir2)\n",
    "update_trials(dir3)\n",
    "update_trials(dir4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-27 13:23:20,017 - INFO - ==== Starting data train+val split script ====\n",
      "==== Starting data train+val split script ====\n",
      "2024-06-27 13:23:20,071 - INFO - Splitting indices...\n",
      "Splitting indices...\n",
      "# of indices:  32646\n",
      "2024-06-27 13:23:20,084 - INFO - Splitting datasets into train and validation sets...\n",
      "Splitting datasets into train and validation sets...\n",
      "2024-06-27 13:23:20,084 - INFO - Processing language: en\n",
      "Processing language: en\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/annavisman/stack/RUG/CS/Year3/thesis/thesis-llm-privacy/split_train_val.py\", line 155, in <module>\n",
      "    main()\n",
      "  File \"/Users/annavisman/stack/RUG/CS/Year3/thesis/thesis-llm-privacy/split_train_val.py\", line 135, in main\n",
      "    with open(os.path.join(dataset_path + \".jsonl\") , \"r\") as f, open(indices_file, \"r\") as idx_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'test/100/EMEA-c.en.jsonl'\n"
     ]
    }
   ],
   "source": [
    "# Step 3. (optional) Split data to train and eval sets to train the model\n",
    "\n",
    "# This will be done for both languages\n",
    "# model size not relevant here, put in any config file as input\n",
    "\n",
    "# 11k examples in data: 10k in train, 1k in eval\n",
    "!python split_train_val.py --config_file config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:37:24,492 - INFO\n",
      "===== Starting dataset token split generation for language en with token length 250 =====\n",
      "2024-06-18 17:37:24,493 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.en-train.jsonl\n",
      "2024-06-18 17:37:24,565 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:37:24,594 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:37:24,623 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:37:24,653 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:37:24,681 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:37:24,709 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:37:24,738 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:37:24,765 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:37:24,794 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:37:24,822 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:37:24,850 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:37:24,878 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:37:24,905 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:37:24,933 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:37:24,961 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:37:24,987 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:37:25,016 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:37:25,043 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:37:25,071 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:37:25,099 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:37:25,128 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:37:25,156 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:37:25,184 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:37:25,211 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:37:25,239 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:37:25,268 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:37:25,295 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:37:25,323 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:37:25,350 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:37:25,377 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:37:25,405 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:37:25,432 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:37:25,459 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:37:25,487 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:37:25,516 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:37:25,544 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:37:25,572 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:37:25,600 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:37:25,626 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:37:25,654 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:37:25,683 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:37:25,711 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:37:25,739 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:37:25,767 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:37:25,793 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:37:25,823 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:37:25,851 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:37:25,878 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:37:25,907 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:37:25,934 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:37:25,961 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:37:25,990 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:37:26,017 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:37:26,044 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:37:26,072 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:37:26,101 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:37:26,129 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:37:26,159 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:37:26,186 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:37:26,213 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:37:26,240 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:37:26,267 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:37:26,297 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:37:26,326 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:37:26,354 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:37:26,382 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:37:26,410 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:37:26,438 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:37:26,466 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:37:26,495 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:37:26,522 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:37:26,551 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:37:26,578 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:37:26,606 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:37:26,636 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:37:26,664 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:37:26,693 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:37:26,721 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:37:26,748 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:37:26,775 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:37:26,802 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:37:26,831 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:37:26,859 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:37:26,888 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:37:26,916 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:37:26,944 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:37:26,971 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:37:26,998 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:37:27,026 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:37:27,054 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:37:27,083 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:37:27,111 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:37:27,138 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:37:27,167 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:37:27,198 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:37:27,226 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:37:27,254 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:37:27,283 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:37:27,310 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:37:27,337 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:37:27,364 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:37:27,392 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:37:27,419 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:37:27,448 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:37:27,475 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:37:27,504 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:37:27,532 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:37:27,560 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:37:27,588 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:37:27,615 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:37:27,642 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:37:27,667 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:37:27,692 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:37:27,717 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:37:27,742 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:37:27,771 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:37:27,825 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:37:27,859 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:37:27,890 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:37:27,918 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:37:27,945 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:37:27,974 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:37:28,003 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:37:28,031 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:37:28,058 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:37:28,085 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:37:28,124 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:37:28,151 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:37:28,177 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:37:28,205 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:37:28,232 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:37:28,258 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:37:28,285 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:37:28,313 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:37:28,346 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:37:28,373 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:37:28,402 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:37:28,430 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:37:28,457 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:37:28,486 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:37:28,513 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:37:28,541 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:37:28,566 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:37:28,592 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:37:28,619 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:37:28,646 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:37:28,673 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:37:28,701 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:37:28,729 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:37:28,756 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:37:28,784 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:37:28,810 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:37:28,835 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:37:28,861 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:37:29,016 - INFO\n",
      "===== Done ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:37:30,940 - INFO\n",
      "===== Starting dataset token split generation for language en with token length 250 =====\n",
      "2024-06-18 17:37:30,940 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.en-train.jsonl\n",
      "2024-06-18 17:37:30,973 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:37:31,003 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:37:31,030 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:37:31,058 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:37:31,085 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:37:31,113 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:37:31,142 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:37:31,170 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:37:31,198 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:37:31,225 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:37:31,252 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:37:31,279 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:37:31,306 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:37:31,334 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:37:31,363 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:37:31,391 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:37:31,419 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:37:31,448 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:37:31,476 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:37:31,505 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:37:31,535 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:37:31,564 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:37:31,592 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:37:31,621 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:37:31,649 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:37:31,677 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:37:31,706 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:37:31,734 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:37:31,762 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:37:31,792 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:37:31,820 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:37:31,850 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:37:31,878 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:37:31,907 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:37:31,935 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:37:31,964 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:37:31,992 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:37:32,020 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:37:32,047 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:37:32,075 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:37:32,104 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:37:32,132 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:37:32,159 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:37:32,186 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:37:32,213 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:37:32,240 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:37:32,267 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:37:32,295 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:37:32,322 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:37:32,349 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:37:32,376 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:37:32,404 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:37:32,431 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:37:32,460 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:37:32,487 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:37:32,516 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:37:32,545 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:37:32,573 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:37:32,600 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:37:32,628 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:37:32,655 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:37:32,684 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:37:32,712 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:37:32,739 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:37:32,767 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:37:32,795 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:37:32,822 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:37:32,850 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:37:32,877 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:37:32,905 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:37:32,932 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:37:32,960 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:37:32,987 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:37:33,013 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:37:33,042 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:37:33,069 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:37:33,096 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:37:33,124 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:37:33,151 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:37:33,178 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:37:33,205 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:37:33,234 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:37:33,266 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:37:33,293 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:37:33,321 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:37:33,348 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:37:33,375 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:37:33,402 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:37:33,430 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:37:33,458 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:37:33,486 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:37:33,514 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:37:33,542 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:37:33,571 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:37:33,599 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:37:33,627 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:37:33,655 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:37:33,683 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:37:33,710 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:37:33,737 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:37:33,763 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:37:33,790 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:37:33,818 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:37:33,846 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:37:33,874 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:37:33,901 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:37:33,928 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:37:33,955 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:37:33,982 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:37:34,009 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:37:34,036 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:37:34,064 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:37:34,090 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:37:34,117 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:37:34,145 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:37:34,172 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:37:34,225 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:37:34,253 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:37:34,281 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:37:34,308 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:37:34,336 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:37:34,364 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:37:34,392 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:37:34,420 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:37:34,448 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:37:34,488 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:37:34,517 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:37:34,546 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:37:34,576 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:37:34,604 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:37:34,633 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:37:34,662 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:37:34,689 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:37:34,717 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:37:34,745 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:37:34,772 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:37:34,801 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:37:34,828 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:37:34,858 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:37:34,887 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:37:34,915 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:37:34,944 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:37:34,972 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:37:34,999 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:37:35,027 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:37:35,054 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:37:35,082 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:37:35,109 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:37:35,136 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:37:35,169 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:37:35,198 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:37:35,226 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:37:35,254 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:37:35,283 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:37:35,452 - INFO\n",
      "===== Done ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:37:37,406 - INFO\n",
      "===== Starting dataset token split generation for language en with token length 250 =====\n",
      "2024-06-18 17:37:37,406 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.en-train.jsonl\n",
      "2024-06-18 17:37:37,441 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:37:37,471 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:37:37,500 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:37:37,531 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:37:37,559 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:37:37,587 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:37:37,614 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:37:37,642 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:37:37,671 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:37:37,700 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:37:37,727 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:37:37,754 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:37:37,783 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:37:37,820 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:37:37,850 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:37:37,878 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:37:37,908 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:37:37,936 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:37:37,966 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:37:37,996 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:37:38,025 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:37:38,057 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:37:38,086 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:37:38,115 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:37:38,143 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:37:38,172 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:37:38,200 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:37:38,228 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:37:38,256 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:37:38,285 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:37:38,312 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:37:38,339 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:37:38,367 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:37:38,394 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:37:38,422 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:37:38,450 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:37:38,478 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:37:38,507 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:37:38,534 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:37:38,562 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:37:38,591 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:37:38,618 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:37:38,646 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:37:38,674 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:37:38,701 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:37:38,729 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:37:38,756 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:37:38,784 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:37:38,812 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:37:38,839 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:37:38,866 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:37:38,894 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:37:38,921 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:37:38,948 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:37:38,975 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:37:39,002 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:37:39,030 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:37:39,058 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:37:39,085 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:37:39,113 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:37:39,142 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:37:39,170 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:37:39,201 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:37:39,229 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:37:39,259 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:37:39,286 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:37:39,313 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:37:39,340 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:37:39,368 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:37:39,396 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:37:39,423 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:37:39,451 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:37:39,480 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:37:39,508 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:37:39,538 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:37:39,566 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:37:39,593 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:37:39,622 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:37:39,650 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:37:39,677 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:37:39,705 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:37:39,733 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:37:39,763 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:37:39,791 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:37:39,820 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:37:39,847 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:37:39,875 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:37:39,903 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:37:39,930 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:37:39,958 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:37:39,986 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:37:40,014 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:37:40,056 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:37:40,091 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:37:40,122 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:37:40,154 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:37:40,184 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:37:40,213 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:37:40,241 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:37:40,274 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:37:40,304 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:37:40,332 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:37:40,360 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:37:40,388 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:37:40,417 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:37:40,446 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:37:40,475 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:37:40,505 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:37:40,536 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:37:40,564 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:37:40,594 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:37:40,622 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:37:40,651 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:37:40,683 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:37:40,713 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:37:40,744 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:37:40,772 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:37:40,828 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:37:40,857 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:37:40,885 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:37:40,913 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:37:40,941 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:37:40,969 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:37:40,996 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:37:41,022 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:37:41,064 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:37:41,092 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:37:41,120 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:37:41,149 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:37:41,176 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:37:41,203 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:37:41,231 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:37:41,257 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:37:41,286 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:37:41,316 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:37:41,345 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:37:41,375 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:37:41,403 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:37:41,430 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:37:41,459 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:37:41,486 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:37:41,513 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:37:41,541 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:37:41,570 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:37:41,597 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:37:41,625 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:37:41,653 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:37:41,681 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:37:41,709 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:37:41,738 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:37:41,765 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:37:41,792 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:37:41,819 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:37:41,847 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:37:42,015 - INFO\n",
      "===== Done ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:37:43,980 - INFO\n",
      "===== Starting dataset token split generation for language en with token length 250 =====\n",
      "2024-06-18 17:37:43,981 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.en-train.jsonl\n",
      "2024-06-18 17:37:44,013 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:37:44,043 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:37:44,070 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:37:44,100 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:37:44,127 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:37:44,156 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:37:44,184 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:37:44,211 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:37:44,240 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:37:44,267 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:37:44,295 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:37:44,322 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:37:44,350 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:37:44,378 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:37:44,405 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:37:44,432 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:37:44,461 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:37:44,488 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:37:44,523 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:37:44,551 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:37:44,578 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:37:44,606 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:37:44,634 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:37:44,662 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:37:44,689 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:37:44,716 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:37:44,744 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:37:44,773 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:37:44,801 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:37:44,828 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:37:44,856 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:37:44,884 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:37:44,911 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:37:44,939 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:37:44,966 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:37:44,994 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:37:45,021 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:37:45,049 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:37:45,077 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:37:45,104 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:37:45,133 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:37:45,160 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:37:45,188 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:37:45,216 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:37:45,242 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:37:45,270 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:37:45,297 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:37:45,324 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:37:45,352 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:37:45,380 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:37:45,408 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:37:45,436 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:37:45,463 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:37:45,490 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:37:45,518 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:37:45,545 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:37:45,573 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:37:45,601 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:37:45,628 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:37:45,656 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:37:45,684 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:37:45,712 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:37:45,739 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:37:45,767 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:37:45,795 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:37:45,822 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:37:45,849 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:37:45,877 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:37:45,905 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:37:45,933 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:37:45,960 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:37:45,988 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:37:46,016 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:37:46,042 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:37:46,071 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:37:46,098 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:37:46,125 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:37:46,153 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:37:46,180 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:37:46,207 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:37:46,234 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:37:46,261 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:37:46,290 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:37:46,318 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:37:46,346 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:37:46,374 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:37:46,402 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:37:46,430 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:37:46,458 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:37:46,486 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:37:46,514 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:37:46,543 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:37:46,571 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:37:46,600 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:37:46,628 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:37:46,655 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:37:46,682 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:37:46,709 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:37:46,738 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:37:46,765 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:37:46,793 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:37:46,820 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:37:46,847 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:37:46,874 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:37:46,903 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:37:46,930 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:37:46,958 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:37:46,985 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:37:47,014 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:37:47,041 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:37:47,070 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:37:47,098 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:37:47,125 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:37:47,152 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:37:47,180 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:37:47,208 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:37:47,236 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:37:47,264 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:37:47,292 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:37:47,319 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:37:47,346 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:37:47,374 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:37:47,402 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:37:47,429 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:37:47,480 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:37:47,512 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:37:47,540 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:37:47,569 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:37:47,597 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:37:47,625 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:37:47,653 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:37:47,680 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:37:47,708 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:37:47,736 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:37:47,764 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:37:47,803 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:37:47,831 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:37:47,859 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:37:47,886 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:37:47,913 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:37:47,941 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:37:47,968 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:37:47,996 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:37:48,023 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:37:48,051 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:37:48,078 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:37:48,106 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:37:48,133 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:37:48,160 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:37:48,188 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:37:48,215 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:37:48,242 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:37:48,270 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:37:48,300 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:37:48,467 - INFO\n",
      "===== Done ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:37:50,507 - INFO\n",
      "===== Starting dataset token split generation for language nl with token length 250 =====\n",
      "2024-06-18 17:37:50,507 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.nl-train.jsonl\n",
      "2024-06-18 17:37:50,572 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:37:50,594 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:37:50,613 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:37:50,634 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:37:50,654 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:37:50,674 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:37:50,693 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:37:50,713 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:37:50,734 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:37:50,756 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:37:50,776 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:37:50,796 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:37:50,815 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:37:50,835 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:37:50,856 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:37:50,876 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:37:50,896 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:37:50,916 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:37:50,936 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:37:50,957 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:37:50,977 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:37:50,996 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:37:51,017 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:37:51,037 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:37:51,057 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:37:51,076 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:37:51,097 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:37:51,117 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:37:51,136 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:37:51,157 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:37:51,178 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:37:51,198 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:37:51,217 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:37:51,237 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:37:51,258 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:37:51,277 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:37:51,296 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:37:51,316 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:37:51,336 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:37:51,356 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:37:51,376 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:37:51,398 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:37:51,418 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:37:51,438 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:37:51,459 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:37:51,498 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:37:51,519 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:37:51,540 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:37:51,561 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:37:51,580 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:37:51,600 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:37:51,621 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:37:51,640 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:37:51,659 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:37:51,680 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:37:51,699 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:37:51,719 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:37:51,744 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:37:51,765 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:37:51,785 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:37:51,805 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:37:51,825 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:37:51,845 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:37:51,865 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:37:51,884 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:37:51,904 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:37:51,924 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:37:51,944 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:37:51,965 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:37:51,985 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:37:52,004 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:37:52,025 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:37:52,045 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:37:52,065 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:37:52,085 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:37:52,105 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:37:52,125 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:37:52,145 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:37:52,164 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:37:52,184 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:37:52,204 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:37:52,224 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:37:52,242 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:37:52,262 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:37:52,282 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:37:52,301 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:37:52,320 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:37:52,339 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:37:52,359 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:37:52,378 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:37:52,397 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:37:52,417 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:37:52,436 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:37:52,456 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:37:52,476 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:37:52,495 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:37:52,514 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:37:52,533 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:37:52,552 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:37:52,571 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:37:52,591 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:37:52,610 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:37:52,629 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:37:52,649 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:37:52,669 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:37:52,689 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:37:52,708 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:37:52,729 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:37:52,748 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:37:52,767 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:37:52,787 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:37:52,806 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:37:52,825 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:37:52,844 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:37:52,864 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:37:52,885 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:37:52,905 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:37:52,924 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:37:52,943 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:37:52,964 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:37:52,983 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:37:53,002 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:37:53,022 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:37:53,043 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:37:53,063 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:37:53,083 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:37:53,115 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:37:53,135 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:37:53,154 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:37:53,175 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:37:53,195 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:37:53,215 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:37:53,235 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:37:53,255 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:37:53,276 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:37:53,296 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:37:53,317 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:37:53,337 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:37:53,357 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:37:53,377 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:37:53,396 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:37:53,416 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:37:53,436 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:37:53,456 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:37:53,476 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:37:53,495 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:37:53,514 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:37:53,534 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:37:53,554 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:37:53,574 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:37:53,594 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:37:53,613 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:37:53,633 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:37:53,652 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:37:53,819 - INFO\n",
      "===== Done ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:37:55,776 - INFO\n",
      "===== Starting dataset token split generation for language nl with token length 250 =====\n",
      "2024-06-18 17:37:55,776 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.nl-train.jsonl\n",
      "2024-06-18 17:37:55,799 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:37:55,821 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:37:55,842 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:37:55,863 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:37:55,889 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:37:55,929 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:37:55,949 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:37:55,969 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:37:55,990 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:37:56,009 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:37:56,029 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:37:56,049 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:37:56,069 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:37:56,090 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:37:56,111 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:37:56,131 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:37:56,152 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:37:56,172 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:37:56,192 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:37:56,212 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:37:56,232 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:37:56,252 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:37:56,273 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:37:56,293 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:37:56,312 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:37:56,332 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:37:56,351 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:37:56,371 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:37:56,390 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:37:56,411 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:37:56,430 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:37:56,450 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:37:56,470 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:37:56,489 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:37:56,509 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:37:56,528 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:37:56,547 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:37:56,566 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:37:56,585 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:37:56,606 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:37:56,625 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:37:56,645 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:37:56,664 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:37:56,683 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:37:56,702 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:37:56,722 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:37:56,742 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:37:56,762 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:37:56,782 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:37:56,802 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:37:56,821 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:37:56,842 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:37:56,862 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:37:56,881 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:37:56,900 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:37:56,919 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:37:56,939 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:37:56,959 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:37:56,978 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:37:56,997 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:37:57,017 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:37:57,037 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:37:57,057 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:37:57,077 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:37:57,096 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:37:57,115 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:37:57,135 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:37:57,154 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:37:57,173 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:37:57,193 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:37:57,213 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:37:57,232 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:37:57,253 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:37:57,272 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:37:57,291 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:37:57,311 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:37:57,330 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:37:57,350 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:37:57,369 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:37:57,389 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:37:57,409 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:37:57,428 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:37:57,448 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:37:57,467 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:37:57,487 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:37:57,506 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:37:57,527 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:37:57,547 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:37:57,567 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:37:57,587 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:37:57,607 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:37:57,626 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:37:57,646 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:37:57,667 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:37:57,686 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:37:57,705 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:37:57,724 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:37:57,744 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:37:57,763 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:37:57,783 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:37:57,802 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:37:57,821 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:37:57,841 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:37:57,861 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:37:57,881 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:37:57,901 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:37:57,919 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:37:57,939 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:37:57,959 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:37:57,978 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:37:57,998 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:37:58,017 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:37:58,036 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:37:58,055 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:37:58,076 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:37:58,096 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:37:58,116 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:37:58,136 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:37:58,156 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:37:58,176 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:37:58,196 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:37:58,216 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:37:58,235 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:37:58,255 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:37:58,275 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:37:58,305 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:37:58,326 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:37:58,345 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:37:58,365 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:37:58,385 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:37:58,403 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:37:58,423 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:37:58,442 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:37:58,462 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:37:58,482 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:37:58,502 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:37:58,523 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:37:58,544 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:37:58,564 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:37:58,584 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:37:58,604 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:37:58,624 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:37:58,644 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:37:58,663 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:37:58,682 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:37:58,702 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:37:58,722 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:37:58,743 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:37:58,763 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:37:58,783 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:37:58,803 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:37:58,823 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:37:58,848 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:37:58,869 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:37:59,029 - INFO\n",
      "===== Done ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:38:01,006 - INFO\n",
      "===== Starting dataset token split generation for language nl with token length 250 =====\n",
      "2024-06-18 17:38:01,006 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.nl-train.jsonl\n",
      "2024-06-18 17:38:01,031 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:38:01,053 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:38:01,075 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:38:01,095 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:38:01,116 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:38:01,135 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:38:01,153 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:38:01,173 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:38:01,192 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:38:01,211 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:38:01,231 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:38:01,251 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:38:01,270 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:38:01,292 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:38:01,312 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:38:01,330 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:38:01,351 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:38:01,371 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:38:01,391 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:38:01,411 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:38:01,430 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:38:01,449 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:38:01,470 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:38:01,489 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:38:01,509 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:38:01,528 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:38:01,548 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:38:01,569 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:38:01,588 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:38:01,609 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:38:01,628 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:38:01,649 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:38:01,669 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:38:01,690 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:38:01,709 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:38:01,730 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:38:01,750 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:38:01,769 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:38:01,790 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:38:01,810 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:38:01,832 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:38:01,852 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:38:01,873 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:38:01,893 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:38:01,912 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:38:01,933 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:38:01,953 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:38:01,974 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:38:01,994 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:38:02,014 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:38:02,033 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:38:02,054 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:38:02,075 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:38:02,095 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:38:02,115 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:38:02,134 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:38:02,153 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:38:02,173 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:38:02,193 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:38:02,215 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:38:02,235 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:38:02,256 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:38:02,277 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:38:02,298 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:38:02,318 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:38:02,337 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:38:02,358 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:38:02,378 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:38:02,398 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:38:02,418 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:38:02,439 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:38:02,458 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:38:02,479 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:38:02,499 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:38:02,520 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:38:02,539 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:38:02,559 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:38:02,578 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:38:02,598 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:38:02,619 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:38:02,639 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:38:02,659 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:38:02,680 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:38:02,700 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:38:02,719 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:38:02,739 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:38:02,759 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:38:02,779 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:38:02,800 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:38:02,820 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:38:02,840 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:38:02,859 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:38:02,880 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:38:02,901 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:38:02,921 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:38:02,941 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:38:02,960 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:38:02,980 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:38:03,000 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:38:03,019 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:38:03,040 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:38:03,059 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:38:03,079 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:38:03,099 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:38:03,120 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:38:03,140 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:38:03,160 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:38:03,179 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:38:03,200 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:38:03,220 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:38:03,240 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:38:03,260 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:38:03,280 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:38:03,300 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:38:03,322 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:38:03,343 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:38:03,363 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:38:03,383 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:38:03,403 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:38:03,422 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:38:03,441 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:38:03,461 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:38:03,481 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:38:03,501 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:38:03,520 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:38:03,550 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:38:03,570 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:38:03,591 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:38:03,610 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:38:03,630 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:38:03,650 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:38:03,670 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:38:03,690 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:38:03,709 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:38:03,730 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:38:03,750 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:38:03,770 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:38:03,791 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:38:03,812 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:38:03,832 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:38:03,853 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:38:03,872 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:38:03,893 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:38:03,913 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:38:03,936 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:38:03,956 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:38:03,976 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:38:03,996 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:38:04,017 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:38:04,036 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:38:04,056 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:38:04,075 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:38:04,120 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:38:04,142 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:38:04,323 - INFO\n",
      "===== Done ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:38:06,376 - INFO\n",
      "===== Starting dataset token split generation for language nl with token length 250 =====\n",
      "2024-06-18 17:38:06,376 - INFO\n",
      "Opened file: EMEA/250/EMEA-c-250.nl-train.jsonl\n",
      "2024-06-18 17:38:06,400 - INFO\n",
      "Processed 64 lines\n",
      "2024-06-18 17:38:06,423 - INFO\n",
      "Processed 128 lines\n",
      "2024-06-18 17:38:06,444 - INFO\n",
      "Processed 192 lines\n",
      "2024-06-18 17:38:06,464 - INFO\n",
      "Processed 256 lines\n",
      "2024-06-18 17:38:06,485 - INFO\n",
      "Processed 320 lines\n",
      "2024-06-18 17:38:06,506 - INFO\n",
      "Processed 384 lines\n",
      "2024-06-18 17:38:06,525 - INFO\n",
      "Processed 448 lines\n",
      "2024-06-18 17:38:06,545 - INFO\n",
      "Processed 512 lines\n",
      "2024-06-18 17:38:06,564 - INFO\n",
      "Processed 576 lines\n",
      "2024-06-18 17:38:06,583 - INFO\n",
      "Processed 640 lines\n",
      "2024-06-18 17:38:06,602 - INFO\n",
      "Processed 704 lines\n",
      "2024-06-18 17:38:06,621 - INFO\n",
      "Processed 768 lines\n",
      "2024-06-18 17:38:06,642 - INFO\n",
      "Processed 832 lines\n",
      "2024-06-18 17:38:06,661 - INFO\n",
      "Processed 896 lines\n",
      "2024-06-18 17:38:06,680 - INFO\n",
      "Processed 960 lines\n",
      "2024-06-18 17:38:06,700 - INFO\n",
      "Processed 1024 lines\n",
      "2024-06-18 17:38:06,721 - INFO\n",
      "Processed 1088 lines\n",
      "2024-06-18 17:38:06,741 - INFO\n",
      "Processed 1152 lines\n",
      "2024-06-18 17:38:06,760 - INFO\n",
      "Processed 1216 lines\n",
      "2024-06-18 17:38:06,778 - INFO\n",
      "Processed 1280 lines\n",
      "2024-06-18 17:38:06,798 - INFO\n",
      "Processed 1344 lines\n",
      "2024-06-18 17:38:06,818 - INFO\n",
      "Processed 1408 lines\n",
      "2024-06-18 17:38:06,838 - INFO\n",
      "Processed 1472 lines\n",
      "2024-06-18 17:38:06,857 - INFO\n",
      "Processed 1536 lines\n",
      "2024-06-18 17:38:06,876 - INFO\n",
      "Processed 1600 lines\n",
      "2024-06-18 17:38:06,895 - INFO\n",
      "Processed 1664 lines\n",
      "2024-06-18 17:38:06,913 - INFO\n",
      "Processed 1728 lines\n",
      "2024-06-18 17:38:06,932 - INFO\n",
      "Processed 1792 lines\n",
      "2024-06-18 17:38:06,951 - INFO\n",
      "Processed 1856 lines\n",
      "2024-06-18 17:38:06,971 - INFO\n",
      "Processed 1920 lines\n",
      "2024-06-18 17:38:06,990 - INFO\n",
      "Processed 1984 lines\n",
      "2024-06-18 17:38:07,009 - INFO\n",
      "Processed 2048 lines\n",
      "2024-06-18 17:38:07,027 - INFO\n",
      "Processed 2112 lines\n",
      "2024-06-18 17:38:07,046 - INFO\n",
      "Processed 2176 lines\n",
      "2024-06-18 17:38:07,066 - INFO\n",
      "Processed 2240 lines\n",
      "2024-06-18 17:38:07,087 - INFO\n",
      "Processed 2304 lines\n",
      "2024-06-18 17:38:07,106 - INFO\n",
      "Processed 2368 lines\n",
      "2024-06-18 17:38:07,124 - INFO\n",
      "Processed 2432 lines\n",
      "2024-06-18 17:38:07,143 - INFO\n",
      "Processed 2496 lines\n",
      "2024-06-18 17:38:07,162 - INFO\n",
      "Processed 2560 lines\n",
      "2024-06-18 17:38:07,181 - INFO\n",
      "Processed 2624 lines\n",
      "2024-06-18 17:38:07,202 - INFO\n",
      "Processed 2688 lines\n",
      "2024-06-18 17:38:07,221 - INFO\n",
      "Processed 2752 lines\n",
      "2024-06-18 17:38:07,239 - INFO\n",
      "Processed 2816 lines\n",
      "2024-06-18 17:38:07,257 - INFO\n",
      "Processed 2880 lines\n",
      "2024-06-18 17:38:07,277 - INFO\n",
      "Processed 2944 lines\n",
      "2024-06-18 17:38:07,296 - INFO\n",
      "Processed 3008 lines\n",
      "2024-06-18 17:38:07,315 - INFO\n",
      "Processed 3072 lines\n",
      "2024-06-18 17:38:07,336 - INFO\n",
      "Processed 3136 lines\n",
      "2024-06-18 17:38:07,354 - INFO\n",
      "Processed 3200 lines\n",
      "2024-06-18 17:38:07,373 - INFO\n",
      "Processed 3264 lines\n",
      "2024-06-18 17:38:07,393 - INFO\n",
      "Processed 3328 lines\n",
      "2024-06-18 17:38:07,411 - INFO\n",
      "Processed 3392 lines\n",
      "2024-06-18 17:38:07,430 - INFO\n",
      "Processed 3456 lines\n",
      "2024-06-18 17:38:07,448 - INFO\n",
      "Processed 3520 lines\n",
      "2024-06-18 17:38:07,467 - INFO\n",
      "Processed 3584 lines\n",
      "2024-06-18 17:38:07,486 - INFO\n",
      "Processed 3648 lines\n",
      "2024-06-18 17:38:07,505 - INFO\n",
      "Processed 3712 lines\n",
      "2024-06-18 17:38:07,525 - INFO\n",
      "Processed 3776 lines\n",
      "2024-06-18 17:38:07,545 - INFO\n",
      "Processed 3840 lines\n",
      "2024-06-18 17:38:07,563 - INFO\n",
      "Processed 3904 lines\n",
      "2024-06-18 17:38:07,584 - INFO\n",
      "Processed 3968 lines\n",
      "2024-06-18 17:38:07,604 - INFO\n",
      "Processed 4032 lines\n",
      "2024-06-18 17:38:07,623 - INFO\n",
      "Processed 4096 lines\n",
      "2024-06-18 17:38:07,642 - INFO\n",
      "Processed 4160 lines\n",
      "2024-06-18 17:38:07,661 - INFO\n",
      "Processed 4224 lines\n",
      "2024-06-18 17:38:07,680 - INFO\n",
      "Processed 4288 lines\n",
      "2024-06-18 17:38:07,700 - INFO\n",
      "Processed 4352 lines\n",
      "2024-06-18 17:38:07,721 - INFO\n",
      "Processed 4416 lines\n",
      "2024-06-18 17:38:07,742 - INFO\n",
      "Processed 4480 lines\n",
      "2024-06-18 17:38:07,761 - INFO\n",
      "Processed 4544 lines\n",
      "2024-06-18 17:38:07,780 - INFO\n",
      "Processed 4608 lines\n",
      "2024-06-18 17:38:07,799 - INFO\n",
      "Processed 4672 lines\n",
      "2024-06-18 17:38:07,818 - INFO\n",
      "Processed 4736 lines\n",
      "2024-06-18 17:38:07,838 - INFO\n",
      "Processed 4800 lines\n",
      "2024-06-18 17:38:07,858 - INFO\n",
      "Processed 4864 lines\n",
      "2024-06-18 17:38:07,877 - INFO\n",
      "Processed 4928 lines\n",
      "2024-06-18 17:38:07,898 - INFO\n",
      "Processed 4992 lines\n",
      "2024-06-18 17:38:07,917 - INFO\n",
      "Processed 5056 lines\n",
      "2024-06-18 17:38:07,941 - INFO\n",
      "Processed 5120 lines\n",
      "2024-06-18 17:38:07,961 - INFO\n",
      "Processed 5184 lines\n",
      "2024-06-18 17:38:07,980 - INFO\n",
      "Processed 5248 lines\n",
      "2024-06-18 17:38:07,999 - INFO\n",
      "Processed 5312 lines\n",
      "2024-06-18 17:38:08,019 - INFO\n",
      "Processed 5376 lines\n",
      "2024-06-18 17:38:08,038 - INFO\n",
      "Processed 5440 lines\n",
      "2024-06-18 17:38:08,056 - INFO\n",
      "Processed 5504 lines\n",
      "2024-06-18 17:38:08,077 - INFO\n",
      "Processed 5568 lines\n",
      "2024-06-18 17:38:08,096 - INFO\n",
      "Processed 5632 lines\n",
      "2024-06-18 17:38:08,115 - INFO\n",
      "Processed 5696 lines\n",
      "2024-06-18 17:38:08,134 - INFO\n",
      "Processed 5760 lines\n",
      "2024-06-18 17:38:08,156 - INFO\n",
      "Processed 5824 lines\n",
      "2024-06-18 17:38:08,175 - INFO\n",
      "Processed 5888 lines\n",
      "2024-06-18 17:38:08,194 - INFO\n",
      "Processed 5952 lines\n",
      "2024-06-18 17:38:08,215 - INFO\n",
      "Processed 6016 lines\n",
      "2024-06-18 17:38:08,234 - INFO\n",
      "Processed 6080 lines\n",
      "2024-06-18 17:38:08,255 - INFO\n",
      "Processed 6144 lines\n",
      "2024-06-18 17:38:08,273 - INFO\n",
      "Processed 6208 lines\n",
      "2024-06-18 17:38:08,292 - INFO\n",
      "Processed 6272 lines\n",
      "2024-06-18 17:38:08,311 - INFO\n",
      "Processed 6336 lines\n",
      "2024-06-18 17:38:08,329 - INFO\n",
      "Processed 6400 lines\n",
      "2024-06-18 17:38:08,347 - INFO\n",
      "Processed 6464 lines\n",
      "2024-06-18 17:38:08,366 - INFO\n",
      "Processed 6528 lines\n",
      "2024-06-18 17:38:08,384 - INFO\n",
      "Processed 6592 lines\n",
      "2024-06-18 17:38:08,403 - INFO\n",
      "Processed 6656 lines\n",
      "2024-06-18 17:38:08,422 - INFO\n",
      "Processed 6720 lines\n",
      "2024-06-18 17:38:08,441 - INFO\n",
      "Processed 6784 lines\n",
      "2024-06-18 17:38:08,461 - INFO\n",
      "Processed 6848 lines\n",
      "2024-06-18 17:38:08,479 - INFO\n",
      "Processed 6912 lines\n",
      "2024-06-18 17:38:08,499 - INFO\n",
      "Processed 6976 lines\n",
      "2024-06-18 17:38:08,518 - INFO\n",
      "Processed 7040 lines\n",
      "2024-06-18 17:38:08,537 - INFO\n",
      "Processed 7104 lines\n",
      "2024-06-18 17:38:08,555 - INFO\n",
      "Processed 7168 lines\n",
      "2024-06-18 17:38:08,575 - INFO\n",
      "Processed 7232 lines\n",
      "2024-06-18 17:38:08,595 - INFO\n",
      "Processed 7296 lines\n",
      "2024-06-18 17:38:08,614 - INFO\n",
      "Processed 7360 lines\n",
      "2024-06-18 17:38:08,633 - INFO\n",
      "Processed 7424 lines\n",
      "2024-06-18 17:38:08,652 - INFO\n",
      "Processed 7488 lines\n",
      "2024-06-18 17:38:08,671 - INFO\n",
      "Processed 7552 lines\n",
      "2024-06-18 17:38:08,690 - INFO\n",
      "Processed 7616 lines\n",
      "2024-06-18 17:38:08,710 - INFO\n",
      "Processed 7680 lines\n",
      "2024-06-18 17:38:08,729 - INFO\n",
      "Processed 7744 lines\n",
      "2024-06-18 17:38:08,748 - INFO\n",
      "Processed 7808 lines\n",
      "2024-06-18 17:38:08,767 - INFO\n",
      "Processed 7872 lines\n",
      "2024-06-18 17:38:08,787 - INFO\n",
      "Processed 7936 lines\n",
      "2024-06-18 17:38:08,807 - INFO\n",
      "Processed 8000 lines\n",
      "2024-06-18 17:38:08,826 - INFO\n",
      "Processed 8064 lines\n",
      "2024-06-18 17:38:08,846 - INFO\n",
      "Processed 8128 lines\n",
      "2024-06-18 17:38:08,865 - INFO\n",
      "Processed 8192 lines\n",
      "2024-06-18 17:38:08,883 - INFO\n",
      "Processed 8256 lines\n",
      "2024-06-18 17:38:08,902 - INFO\n",
      "Processed 8320 lines\n",
      "2024-06-18 17:38:08,921 - INFO\n",
      "Processed 8384 lines\n",
      "2024-06-18 17:38:08,940 - INFO\n",
      "Processed 8448 lines\n",
      "2024-06-18 17:38:08,958 - INFO\n",
      "Processed 8512 lines\n",
      "2024-06-18 17:38:08,978 - INFO\n",
      "Processed 8576 lines\n",
      "2024-06-18 17:38:08,996 - INFO\n",
      "Processed 8640 lines\n",
      "2024-06-18 17:38:09,027 - INFO\n",
      "Processed 8704 lines\n",
      "2024-06-18 17:38:09,047 - INFO\n",
      "Processed 8768 lines\n",
      "2024-06-18 17:38:09,066 - INFO\n",
      "Processed 8832 lines\n",
      "2024-06-18 17:38:09,086 - INFO\n",
      "Processed 8896 lines\n",
      "2024-06-18 17:38:09,105 - INFO\n",
      "Processed 8960 lines\n",
      "2024-06-18 17:38:09,124 - INFO\n",
      "Processed 9024 lines\n",
      "2024-06-18 17:38:09,143 - INFO\n",
      "Processed 9088 lines\n",
      "2024-06-18 17:38:09,162 - INFO\n",
      "Processed 9152 lines\n",
      "2024-06-18 17:38:09,181 - INFO\n",
      "Processed 9216 lines\n",
      "2024-06-18 17:38:09,199 - INFO\n",
      "Processed 9280 lines\n",
      "2024-06-18 17:38:09,217 - INFO\n",
      "Processed 9344 lines\n",
      "2024-06-18 17:38:09,237 - INFO\n",
      "Processed 9408 lines\n",
      "2024-06-18 17:38:09,255 - INFO\n",
      "Processed 9472 lines\n",
      "2024-06-18 17:38:09,274 - INFO\n",
      "Processed 9536 lines\n",
      "2024-06-18 17:38:09,293 - INFO\n",
      "Processed 9600 lines\n",
      "2024-06-18 17:38:09,311 - INFO\n",
      "Processed 9664 lines\n",
      "2024-06-18 17:38:09,330 - INFO\n",
      "Processed 9728 lines\n",
      "2024-06-18 17:38:09,349 - INFO\n",
      "Processed 9792 lines\n",
      "2024-06-18 17:38:09,368 - INFO\n",
      "Processed 9856 lines\n",
      "2024-06-18 17:38:09,529 - INFO\n",
      "===== Done ======\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Split (training) data to (pre)prefix set and suffix set\n",
    "\n",
    "# supply the training dataset here only if you want to split the training data\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG1}.json\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE3}-{LANG1}.json\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE4}-{LANG1}.json\n",
    "\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG2}.json\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE2}-{LANG2}.json\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE3}-{LANG2}.json\n",
    "!python split_dataset.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE4}-{LANG2}.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 13:31:00,922 - INFO - Parsing arguments...\n",
      "Parsing arguments...\n",
      "2024-06-18 13:31:00,923 - INFO - Model directory provided: finetuned/en-100-100-125M\n",
      "Model directory provided: finetuned/en-100-100-125M\n",
      "2024-06-18 13:31:00,923 - INFO - Executing extraction on finetuned model.\n",
      "Executing extraction on finetuned model.\n",
      "2024-06-18 13:31:00,933 - INFO - Default device: mps\n",
      "Default device: mps\n",
      "2024-06-18 13:31:00,933 - INFO - Loading tokenizer...\n",
      "Loading tokenizer...\n",
      "2024-06-18 13:31:01,033 - INFO - Loading model...\n",
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "# Step 5. Train the model + perform extraction\n",
    "\n",
    "# run this directly in terminal, model cannot be loaded in notebook due to memory constraints I think, crashes kernel\n",
    "# NOTE: I cannot run this locally, so I run this on a HPC of the university\n",
    "# Uploaded full contents of datasets + EMEA folders to Habrok so it has all data for training + extraction\n",
    "\n",
    "# !python train.py --config_file exp-configs/EMEA/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG1}.json\n",
    "# !python extraction.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG1}.json --model_dir finetuned/en-100-100-125M --cache_dir cache\n",
    "\n",
    "# !python extraction.py --config_file exp-configs/EMEA/100/config-125M-en.json --model_dir finetuned/en-100-100-125M --cache_dir cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the model generations from the numpy files to jsonl files\n",
    "# NOTE: numpy files have been downloaded from the HPC where they were generated\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "from experiment_lib import (\n",
    "    generations_to_jsonl,\n",
    "    load_constants_from_config,\n",
    "    generate_exid_list,\n",
    ")\n",
    "import json\n",
    "\n",
    "\n",
    "def decode_generations(tokenizer, exids, num_trials, exp_base):\n",
    "    for i in range(0, num_trials):\n",
    "        file_path = os.path.join(exp_base, f\"generations/{i}.npy\")\n",
    "        data = np.load(file_path)\n",
    "        print(f\"Data shape: {str(data.shape)}\")\n",
    "\n",
    "        output_file_path = os.path.join(\n",
    "            exp_base, f\"decoded/decoded_strings_trial_{i}.jsonl\"\n",
    "        )\n",
    "        output_dir = os.path.dirname(output_file_path)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(\"Trial already decoded, skipping...\")\n",
    "        else:\n",
    "            generations_to_jsonl(output_file_path, data, tokenizer, exids)\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "def decoding(path):\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    (\n",
    "        ROOT_DIR,\n",
    "        DATASET_DIR,\n",
    "        SOURCE_DIR,\n",
    "        DATASET_NAME,\n",
    "        EXPERIMENT_NAME,\n",
    "        NUM_TRIALS,\n",
    "        PREFIX_LEN,\n",
    "        SUFFIX_LEN,\n",
    "        PREPREFIX_LEN,\n",
    "        LANGUAGE,\n",
    "        SPLIT,\n",
    "        EXAMPLE_TOKEN_LEN,\n",
    "        SOURCE_FILE,\n",
    "        BATCH_SIZE,\n",
    "        MODEL_NAME,\n",
    "        TRAIN_FILE,\n",
    "        VAL_FILE,\n",
    "        VAL_SPLIT,\n",
    "        SEED,\n",
    "    ) = load_constants_from_config(config)\n",
    "\n",
    "    NUM_TRIALS = 100\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    experiment_base = os.path.join(ROOT_DIR, DATASET_DIR, LANGUAGE, EXPERIMENT_NAME)\n",
    "\n",
    "    # pretain\n",
    "    # exids_path = os.path.join(\n",
    "    #     SOURCE_DIR,\n",
    "    #     DATASET_DIR,\n",
    "    #     \"csv\",\n",
    "    #     str(EXAMPLE_TOKEN_LEN),\n",
    "    #     \"common_exids-\" + str(EXAMPLE_TOKEN_LEN) + \".csv\",\n",
    "    # )\n",
    "    # exids = generate_exid_list(exids_path)\n",
    "\n",
    "    # Train exids only\n",
    "    exids_path = os.path.join(DATASET_DIR, str(EXAMPLE_TOKEN_LEN), \"split_indices.json\")\n",
    "    with open(exids_path, 'r') as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            exids = obj[\"train\"]\n",
    "\n",
    "        print(exids[:10])\n",
    "\n",
    "    decode_generations(tokenizer, exids, NUM_TRIALS, experiment_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8542, 8107, 4428, 10340, 1678, 190, 7870, 5254, 654, 7084]\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_0.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_1.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_2.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_3.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_4.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_5.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_6.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_7.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_8.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_9.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_10.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_11.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_12.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_13.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_14.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_15.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_16.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_17.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_18.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_19.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_20.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_21.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_22.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_23.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_24.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_25.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_26.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_27.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_28.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_29.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_30.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_31.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_32.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_33.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_34.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_35.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_36.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_37.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_38.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_39.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_40.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_41.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_42.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_43.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_44.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_45.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_46.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_47.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_48.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_49.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_50.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_51.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_52.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_53.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_54.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_55.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_56.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_57.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_58.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_59.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_60.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_61.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_62.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_63.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_64.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_65.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_66.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_67.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_68.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_69.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_70.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_71.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_72.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_73.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_74.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_75.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_76.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_77.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_78.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_79.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_80.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_81.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_82.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_83.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_84.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_85.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_86.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_87.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_88.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_89.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_90.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_91.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_92.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_93.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_94.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_95.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_96.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_97.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_98.jsonl\n",
      "Data shape: (9900, 100)\n",
      "Decoded strings saved to: %s tmp/EMEA/en/en-100-100-125M/decoded/decoded_strings_trial_99.jsonl\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# decoding(\"exp-configs/EMEA/150/config-125M-en.json\")\n",
    "# decoding(\"exp-configs/EMEA/200/config-125M-en.json\")\n",
    "# decoding(\"exp-configs/EMEA/250/config-125M-en.json\")\n",
    "\n",
    "decoding(\"exp-configs/EMEA/100/config-125M-en.json\")\n",
    "# decoding(\"exp-configs/EMEA/150/config-125M-nl.json\")\n",
    "# decoding(\"exp-configs/EMEA/200/config-125M-nl.json\")\n",
    "# decoding(\"exp-configs/EMEA/250/config-125M-nl.json\")\n",
    "\n",
    "# decoding(\"exp-configs/EMEA/200/config-1.3B-nl.json\")\n",
    "# decoding(\"exp-configs/EMEA/150/config-1.3B-nl.json\")\n",
    "# decoding(\"exp-configs/EMEA/250/config-1.3B-nl.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-27 23:19:58,864 - INFO - ===== Starting BLEU- & METEOR-score calculation between generated and original text in language en for 50 prefix & suffix length =====\n",
      "===== Starting BLEU- & METEOR-score calculation between generated and original text in language en for 50 prefix & suffix length =====\n",
      "2024-06-27 23:19:58,864 - INFO - ===== Decoding original preprefixes, prefixes & suffixes =====\n",
      "===== Decoding original preprefixes, prefixes & suffixes =====\n",
      "2024-06-27 23:19:58,864 - INFO - Loading split indices from EMEA/100/split_indices.json\n",
      "Loading split indices from EMEA/100/split_indices.json\n",
      "2024-06-27 23:20:00,872 - INFO - Starting BLEU-score calculation for trial 0\n",
      "Starting BLEU-score calculation for trial 0\n",
      "2024-06-27 23:20:00,874 - INFO - Saving BLEU scores for trial 0 to tmp/EMEA/en/en-100-100-125M/bleu_scores/bleu_scores_trial_0.jsonl\n",
      "Saving BLEU scores for trial 0 to tmp/EMEA/en/en-100-100-125M/bleu_scores/bleu_scores_trial_0.jsonl\n",
      "/opt/miniconda3/envs/torch/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/miniconda3/envs/torch/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/miniconda3/envs/torch/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/annavisman/stack/RUG/CS/Year3/thesis/thesis-llm-privacy/calculate_scores.py\", line 266, in <module>\n",
      "    main()\n",
      "  File \"/Users/annavisman/stack/RUG/CS/Year3/thesis/thesis-llm-privacy/calculate_scores.py\", line 177, in main\n",
      "    suffix_ref = tokenizer.tokenize(suffix)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py\", line 403, in tokenize\n",
      "    return self.encode_plus(text=text, text_pair=pair, add_special_tokens=add_special_tokens, **kwargs).tokens()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 3062, in encode_plus\n",
      "    return self._encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\", line 138, in _encode_plus\n",
      "    return super()._encode_plus(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py\", line 583, in _encode_plus\n",
      "    batched_output = self._batch_encode_plus(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\", line 128, in _batch_encode_plus\n",
      "    return super()._batch_encode_plus(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/torch/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py\", line 511, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Calculate BLEU and METEOR scores for the generated outputs\n",
    "\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE2}-{LANG2}.json\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE2}-{LANG2}.json\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/200/config-{MODEL_SIZE2}-{LANG2}.json\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/250/config-{MODEL_SIZE2}-{LANG2}.json\n",
    "\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE3}-{LANG1}.json\n",
    "\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE3}-{LANG1}.json\n",
    "# !python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/200/config-{MODEL_SIZE3}-{LANG1}.json\n",
    "\n",
    "!python calculate_scores.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE1}-{LANG1}.json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-27 11:54:30,301 - INFO\n",
      "Evaluating scores on finetuned model.\n",
      "2024-06-27 11:54:39,226 - INFO\n",
      "==== Starting evaluation ====\n",
      "2024-06-27 11:54:39,226 - INFO\n",
      "Experiment name: en-150-100-1.3B\n",
      "2024-06-27 11:54:39,226 - INFO\n",
      "Language: en\n",
      "2024-06-27 11:54:39,226 - INFO\n",
      "Model: EleutherAI/gpt-neo-1.3B\n",
      "2024-06-27 11:54:39,226 - INFO\n",
      "Loading list of example IDs for dataset EMEA...\n",
      "2024-06-27 11:54:39,227 - INFO\n",
      "Loaded 9900 example IDs\n",
      "2024-06-27 11:54:41,233 - INFO\n",
      "Bleu scores for this experiment previously merged, skipping...\n",
      "2024-06-27 11:54:41,233 - INFO\n",
      "Sorting BLEU scores...\n",
      "2024-06-27 11:54:41,233 - INFO\n",
      "Output file tmp/EMEA/en/en-150-100-1.3B/bleu_scores/sorted_compl_bleu_scores.jsonl already exists and is not empty, skipping...\n",
      "2024-06-27 11:54:41,233 - INFO\n",
      "Sorted BLEU scores saved to tmp/EMEA/en/en-150-100-1.3B/bleu_scores/sorted_compl_bleu_scores.jsonl\n",
      "2024-06-27 11:54:41,233 - INFO\n",
      "Decoding losses...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 0 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 1 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 2 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 3 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 4 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 5 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 6 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 7 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 8 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 9 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 10 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 11 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 12 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 13 already computed, skipping...\n",
      "2024-06-27 11:54:41,235 - INFO\n",
      "Decoded losses for trial 14 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 15 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 16 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 17 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 18 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 19 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 20 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 21 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 22 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 23 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 24 already computed, skipping...\n",
      "2024-06-27 11:54:41,236 - INFO\n",
      "Decoded losses for trial 25 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 26 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 27 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 28 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 29 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 30 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 31 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 32 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 33 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 34 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 35 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 36 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 37 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 38 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 39 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 40 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 41 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 42 already computed, skipping...\n",
      "2024-06-27 11:54:41,237 - INFO\n",
      "Decoded losses for trial 43 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 44 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 45 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 46 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 47 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 48 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 49 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 50 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 51 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 52 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 53 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 54 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 55 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 56 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 57 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 58 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 59 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 60 already computed, skipping...\n",
      "2024-06-27 11:54:41,238 - INFO\n",
      "Decoded losses for trial 61 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 62 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 63 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 64 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 65 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 66 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 67 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 68 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 69 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 70 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 71 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 72 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 73 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 74 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 75 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 76 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 77 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 78 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 79 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 80 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 81 already computed, skipping...\n",
      "2024-06-27 11:54:41,239 - INFO\n",
      "Decoded losses for trial 82 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 83 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 84 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 85 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 86 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 87 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 88 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 89 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 90 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 91 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 92 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 93 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 94 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 95 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 96 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 97 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 98 already computed, skipping...\n",
      "2024-06-27 11:54:41,240 - INFO\n",
      "Decoded losses for trial 99 already computed, skipping...\n",
      "2024-06-27 11:54:56,162 - INFO\n",
      "Output file tmp/EMEA/en/en-150-100-1.3B/losses/decoded/complete_losses.jsonl already exists and is not empty, skipping...\n",
      "2024-06-27 11:54:56,162 - INFO\n",
      "Sorting losses...\n",
      "2024-06-27 11:54:59,106 - INFO\n",
      "Sorted losses saved to tmp/EMEA/en/en-150-100-1.3B/losses/decoded/sorted_compl_losses.jsonl\n",
      "2024-06-27 11:54:59,106 - INFO\n",
      "Calculating perplexities...\n",
      "2024-06-27 11:54:59,106 - INFO\n",
      "Output file tmp/EMEA/en/en-150-100-1.3B/losses/decoded/perplexities.jsonl already exists and is not empty, skipping...\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model outputs: sort and merge scores into single files to simplify analysis & plotting\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG1}.json\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE3}-{LANG1}.json\n",
    "\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG2}.json\n",
    "# !python evalu;.ation.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE2}-{LANG2}.json\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE3}-{LANG2}.json\n",
    "\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE2}-{LANG1}.json --trained True\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE3}-{LANG1}.json --trained True\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE3}-{LANG1}.json --trained True\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE1}-{LANG1}.json --trained True\n",
    "\n",
    "\n",
    "!python evaluation.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE2}-{LANG1}.json --trained True\n",
    "\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE2}-{LANG1}.json --trained True\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/200/config-{MODEL_SIZE2}-{LANG1}.json --trained True\n",
    "# !python evaluation.py --config_file exp-configs/{DATASET_DIR}/250/config-{MODEL_SIZE2}-{LANG1}.json --trained True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-26 23:51:42,309 - INFO - ====== Calculating number of correct guesses (accuracy) for nl-100-100-2.7B in language nl ======\n",
      "====== Calculating number of correct guesses (accuracy) for nl-100-100-2.7B in language nl ======\n",
      "2024-06-26 23:51:42,573 - INFO - Finished counting amount of correct guesses.\n",
      "Finished counting amount of correct guesses.\n",
      "2024-06-26 23:51:42,573 - INFO - Saving output to tmp/EMEA/nl/nl-100-100-2.7B/accuracy.jsonl\n",
      "Saving output to tmp/EMEA/nl/nl-100-100-2.7B/accuracy.jsonl\n",
      "2024-06-26 23:51:42,583 - INFO - ====== Finished calculating number of correct guesses (accuracy) for nl-100-100-2.7B in language nl ======\n",
      "====== Finished calculating number of correct guesses (accuracy) for nl-100-100-2.7B in language nl ======\n",
      "2024-06-26 23:51:44,084 - INFO - ====== Calculating number of correct guesses (accuracy) for nl-150-100-2.7B in language nl ======\n",
      "====== Calculating number of correct guesses (accuracy) for nl-150-100-2.7B in language nl ======\n",
      "2024-06-26 23:51:44,355 - INFO - Finished counting amount of correct guesses.\n",
      "Finished counting amount of correct guesses.\n",
      "2024-06-26 23:51:44,355 - INFO - Saving output to tmp/EMEA/nl/nl-150-100-2.7B/accuracy.jsonl\n",
      "Saving output to tmp/EMEA/nl/nl-150-100-2.7B/accuracy.jsonl\n",
      "2024-06-26 23:51:44,366 - INFO - ====== Finished calculating number of correct guesses (accuracy) for nl-150-100-2.7B in language nl ======\n",
      "====== Finished calculating number of correct guesses (accuracy) for nl-150-100-2.7B in language nl ======\n",
      "2024-06-26 23:51:45,922 - INFO - ====== Calculating number of correct guesses (accuracy) for nl-200-100-2.7B in language nl ======\n",
      "====== Calculating number of correct guesses (accuracy) for nl-200-100-2.7B in language nl ======\n",
      "2024-06-26 23:51:46,087 - INFO - Finished counting amount of correct guesses.\n",
      "Finished counting amount of correct guesses.\n",
      "2024-06-26 23:51:46,087 - INFO - Saving output to tmp/EMEA/nl/nl-200-100-2.7B/accuracy.jsonl\n",
      "Saving output to tmp/EMEA/nl/nl-200-100-2.7B/accuracy.jsonl\n",
      "2024-06-26 23:51:46,097 - INFO - ====== Finished calculating number of correct guesses (accuracy) for nl-200-100-2.7B in language nl ======\n",
      "====== Finished calculating number of correct guesses (accuracy) for nl-200-100-2.7B in language nl ======\n"
     ]
    }
   ],
   "source": [
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG1}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE3}-{LANG1}.json\n",
    "# # !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE4}-{LANG1}.json\n",
    "\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE1}-{LANG2}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE2}-{LANG2}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE3}-{LANG2}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/{EXAMPLE_TOKEN_LEN}/config-{MODEL_SIZE4}-{LANG2}.json\n",
    "\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/200/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "# !python accuracy.py --config_file exp-configs/{DATASET_DIR}/250/config-{MODEL_SIZE2}-{LANG1}.json\n",
    "# !python accuracy.py --config_file exp-configs/EMEA/150/config-125M-nl.json\n",
    "# !python accuracy.py --config_file exp-configs/EMEA/200/config-125M-nl.json\n",
    "# !python accuracy.py --config_file exp-configs/EMEA/250/config-125M-nl.json\n",
    "\n",
    "!python accuracy.py --config_file exp-configs/{DATASET_DIR}/100/config-{MODEL_SIZE3}-{LANG2}.json\n",
    "!python accuracy.py --config_file exp-configs/{DATASET_DIR}/150/config-{MODEL_SIZE3}-{LANG2}.json\n",
    "!python accuracy.py --config_file exp-configs/{DATASET_DIR}/200/config-{MODEL_SIZE3}-{LANG2}.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', ' vol', 'ks', 'ge', 'z', 'ond', 'heid', ' en', ' cons', 'ument', 'en', 'be', 'le', 'id', ',', ' bet', 're', 'ff', 'ende', ' he', 't', ' gem', 'e', 'ens', 'ch', 'app', 'el', 'ijk', ' stand', 'p', 'unt', ',', ' door', ' de', ' Ra', 'ad', ' vast', 'gest', 'e', 'ld', ' met', ' he', 't', ' o', 'og', ' op', ' de', ' a', 'ann', 'eming']\n",
      "[' Van', ' L', 'iet', 't', 'j', 'es', ',', ' z', 'eg', 't', ' he', 't', ' Europe', 'es', ' Par', 'lement', ' om', ' e', 'en', ' z', 'eer', ' g', 'eval', ' op', ' he', 't', ' bel', 'ang', ' van', ' on', 'ze', ' le', 'zing', ' en', ' de', ' on', 'tw', 'ik', 'ke', 'ling', ' van', ' de', ' Euro', 'p', 'ese', ' Un', 'ie', ' (', 'E', 'VE']\n",
      "50\n",
      "50\n",
      "4.591835960079284e-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/miniconda3/envs/torch/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "\n",
    "# Function to calculate the BLEU score between the reference and candidate text\n",
    "def calc_bleu_score(reference, candidate):\n",
    "    return sentence_bleu([reference], candidate)\n",
    "\n",
    "\n",
    "suff_file = \"datasets/europarl/nl/100/EleutherAI/gpt-neo-1.3B/_suffix.jsonl\"\n",
    "with open(suff_file, \"r\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    suffix_lines = file.readlines()\n",
    "\n",
    "index = 1567\n",
    "# index = 19\n",
    "\n",
    "json_line = json.loads(suffix_lines[index])\n",
    "exid = json_line[\"exid\"]\n",
    "suffix = json.loads(suffix_lines[index])[\"text\"].strip()\n",
    "\n",
    "\n",
    "# trial 44 should give 1 for this one\n",
    "# guess = {\"exid\": \"402237\", \"text\": \"Aan de orde is de aanbeveling voor de tweede lezing (A5-0099/2003) van mevrouw Schrling, namens de Commissie milieubeheer, volksgezondheid en consumentenbeleid, betreffende het gemeenschappelijk standpunt, door de Raad vastgesteld met het oog op de aanneming\"}\n",
    "\n",
    "# guess = {\"exid\": \"402237\", \"text\": \"Aan de orde is de aanbeveling voor de tweede lezing (A5-0099/2003) van mevrouw Schrling, namens de Commissie milieubeheer, volksgezondheid en consumentenbescherming, over de mededeling van de Commissie aan de Raad en het Europees Parlement betreffende de voorkoming van de ondoord\"}\n",
    "\n",
    "guess = {\n",
    "    \"exid\": \"402237\",\n",
    "    \"text\": \"Aan de orde is de aanbeveling voor de tweede lezing (A5-0099/2003) van mevrouw Schrling, namens de Commissie milieubeheer Van Liettjes, zegt het Europees Parlement om een zeer geval op het belang van onze lezing en de ontwikkeling van de Europese Unie (EVE\",\n",
    "}\n",
    "\n",
    "candidate = guess[\"text\"]\n",
    "\n",
    "\n",
    "suffix_ref = tokenizer.tokenize(suffix)\n",
    "suffix_ref = [s.replace(\"\", \" \") for s in suffix_ref]\n",
    "cand = tokenizer.tokenize(candidate)\n",
    "\n",
    "\n",
    "cand = cand[50:]\n",
    "suffix_cand = [c.replace(\"\", \" \") for c in cand]\n",
    "\n",
    "\n",
    "print(suffix_ref)\n",
    "print(suffix_cand)\n",
    "\n",
    "print(len(suffix_ref))\n",
    "print(len(suffix_cand))\n",
    "\n",
    "\n",
    "suffix_score = calc_bleu_score(suffix_ref, suffix_cand)\n",
    "print(suffix_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique sentences is 9893.\n",
      "the total number of sentences is 9900.\n"
     ]
    }
   ],
   "source": [
    "# Count numnber of unique sentences\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = np.load(\n",
    "    \"datasets/EMEA/nl/250/EleutherAI/gpt-neo-2.7B/train_dataset.npy\", allow_pickle=True\n",
    ")\n",
    "\n",
    "# Convert the lists of tokens to tuples so they can be put in a set\n",
    "data = [tuple(sentence) for sentence in data]\n",
    "\n",
    "# Count the number of unique sentences\n",
    "num_unique_sentences = len(set(data))\n",
    "\n",
    "print(f\"The number of unique sentences is {num_unique_sentences}.\")\n",
    "print(f\"the total number of sentences is {len(data)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 7_temp.npy to 96.npy\n",
      "Renamed 6_temp.npy to 95.npy\n",
      "Renamed 0_temp.npy to 89.npy\n",
      "Renamed 1_temp.npy to 90.npy\n",
      "Renamed 4_temp.npy to 93.npy\n",
      "Renamed 5_temp.npy to 94.npy\n",
      "Renamed 3_temp.npy to 92.npy\n",
      "Renamed 2_temp.npy to 91.npy\n",
      "Renamed 9_temp.npy to 98.npy\n",
      "Renamed 8_temp.npy to 97.npy\n",
      "Renamed 10_temp.npy to 99.npy\n",
      "Renamed 7_temp.npy to 96.npy\n",
      "Renamed 6_temp.npy to 95.npy\n",
      "Renamed 0_temp.npy to 89.npy\n",
      "Renamed 1_temp.npy to 90.npy\n",
      "Renamed 4_temp.npy to 93.npy\n",
      "Renamed 5_temp.npy to 94.npy\n",
      "Renamed 3_temp.npy to 92.npy\n",
      "Renamed 2_temp.npy to 91.npy\n",
      "Renamed 9_temp.npy to 98.npy\n",
      "Renamed 8_temp.npy to 97.npy\n",
      "Renamed 10_temp.npy to 99.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def rename_npy_files(directory):\n",
    "    # List all files in the specified directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Filter for .npy files\n",
    "    npy_files = [f for f in files if f.endswith(\".npy\")]\n",
    "\n",
    "    # Create a temporary name for each file to avoid conflicts\n",
    "    for file in npy_files:\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "\n",
    "        try:\n",
    "            original_number = int(base_name)\n",
    "            temp_filename = f\"{original_number}_temp.npy\"\n",
    "            original_path = os.path.join(directory, file)\n",
    "            temp_path = os.path.join(directory, temp_filename)\n",
    "            os.rename(original_path, temp_path)\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"Skipping file {file} as it does not have a numeric base name\")\n",
    "\n",
    "    # Rename temporary files to the final names\n",
    "    temp_files = [f for f in os.listdir(directory) if f.endswith(\"_temp.npy\")]\n",
    "\n",
    "    for temp_file in temp_files:\n",
    "        base_name = os.path.splitext(temp_file)[0]\n",
    "\n",
    "        try:\n",
    "            original_number = int(base_name.split(\"_\")[0])\n",
    "            new_number = original_number + 89\n",
    "            new_filename = f\"{new_number}.npy\"\n",
    "            temp_path = os.path.join(directory, temp_file)\n",
    "            final_path = os.path.join(directory, new_filename)\n",
    "            os.rename(temp_path, final_path)\n",
    "\n",
    "            print(f\"Renamed {temp_file} to {new_filename}\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"Skipping file {temp_file} as it does not have a numeric base name\")\n",
    "\n",
    "\n",
    "rename_npy_files(\"tmp/EMEA/en/en-150-100-2.7B-2/generations\")\n",
    "rename_npy_files(\"tmp/EMEA/en/en-150-100-2.7B-2/losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8542, 8107, 4428, 10340, 1678, 190, 7870, 5254, 654, 7084]\n",
      "Decoded strings saved to: %s test/100-125M-en.jsonl\n"
     ]
    }
   ],
   "source": [
    "from experiment_lib import generations_to_jsonl\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "data = np.load(\"datasets/EMEA/en/100/EleutherAI/gpt-neo-125M/train_prefix.npy\")\n",
    "\n",
    "output_file = \"test/100-125M-en.jsonl\"\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "file = \"EMEA/100/split_indices.json\"\n",
    "with open(file, \"r\") as f:\n",
    "    split_indices = json.load(f)\n",
    "            # this gives a list of indices present in the training dataset\n",
    "    exids = split_indices[\"train\"]\n",
    "\n",
    "print(exids[:10])\n",
    "\n",
    "generations_to_jsonl(output_file, data, tokenizer, exids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to combined.npy.\n",
      "Text data saved to combined_text.txt.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "\n",
    "def convert_to_text(data):\n",
    "    # Decode each item in the data array to text\n",
    "    text_data = [tokenizer.decode(item, skip_special_tokens=True) for item in data]\n",
    "    return \"\\n\".join(text_data)\n",
    "\n",
    "def combine_npy_files_and_convert_to_text():\n",
    "    # Load the data from each file\n",
    "    # preprefix_data = np.load('preprefix.npy', allow_pickle=True)\n",
    "    prefix_data = np.load('datasets/EMEA/en/100/EleutherAI/gpt-neo-125M/train_prefix.npy', allow_pickle=True)\n",
    "    suffix_data = np.load('datasets/EMEA/en/100/EleutherAI/gpt-neo-125M/train_suffix.npy', allow_pickle=True)\n",
    "    \n",
    "    # Concatenate the arrays\n",
    "    # combined_data = np.concatenate((preprefix_data, prefix_data, suffix_data))\n",
    "    combined_data = np.concatenate((prefix_data, suffix_data))\n",
    "\n",
    "    # Convert the combined array to text\n",
    "    text_data = convert_to_text(combined_data)\n",
    "    \n",
    "    # Save the combined array to a new file\n",
    "    np.save('test/combined.npy', combined_data)\n",
    "    \n",
    "    # Save the text data to a file\n",
    "    with open('test/combined_text.txt', 'w') as text_file:\n",
    "        text_file.write(text_data)\n",
    "    \n",
    "    print(\"Combined data saved to combined.npy.\")\n",
    "    print(\"Text data saved to combined_text.txt.\")\n",
    "\n",
    "# Call the function to execute the operations\n",
    "combine_npy_files_and_convert_to_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_existence_with_counts(train_file, check_file):\n",
    "    # Read the second file and store sentences in a dictionary with their counts\n",
    "    sentences_dict = {}\n",
    "    with open(train_file, 'r') as f:\n",
    "        for line in f:\n",
    "            sentence = line.strip()\n",
    "            if sentence in sentences_dict:\n",
    "                sentences_dict[sentence] += 1\n",
    "            else:\n",
    "                sentences_dict[sentence] = 1\n",
    "    \n",
    "    count  = 0\n",
    "\n",
    "    # Loop over each sentence in the first file\n",
    "    with open(check_file, 'r') as f:\n",
    "        for sentence in f:\n",
    "            sentence = sentence.strip()\n",
    "            # Check if the sentence is in the dictionary\n",
    "            if sentence in sentences_dict:\n",
    "                # If found, return True\n",
    "                print(\"found\")\n",
    "                count += 1\n",
    "\n",
    "    # If no sentence from the first file is found in the second, return False\n",
    "    return count\n",
    "\n",
    "# Example usage\n",
    "train_set = \"test/train-en.txt\"\n",
    "other_file = \"test/combined_text.txt\"\n",
    "result = check_sentence_existence_with_counts(train_set, other_file)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
