{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:29:34,022 - INFO - Parsing arguments...\n",
      "Parsing arguments...\n",
      "2024-06-11 13:29:34,022 - INFO - Loading tokenizer...\n",
      "Loading tokenizer...\n",
      "2024-06-11 13:29:34,250 - INFO - ==== Starting data preprocessing script ====\n",
      "==== Starting data preprocessing script ====\n",
      "2024-06-11 13:29:34,250 - INFO - This may take a while depending on the size of the dataset...\n",
      "This may take a while depending on the size of the dataset...\n",
      "2024-06-11 13:29:34,250 - INFO - Counting tokens for en...\n",
      "Counting tokens for en...\n",
      "Generating byte offset dataset from file:  EMEA/EMEA.en\n",
      "2024-06-11 13:29:53,468 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.en.csv: 840\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.en.csv: 840\n",
      "2024-06-11 13:29:53,468 - INFO - Counting tokens for nl...\n",
      "Counting tokens for nl...\n",
      "Generating byte offset dataset from file:  EMEA/EMEA.nl\n",
      "2024-06-11 13:30:20,085 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.nl.csv: 3910\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.nl.csv: 3910\n",
      "2024-06-11 13:30:20,086 - INFO - Filtering sentences that are >= 150 tokens to ./datasets/EMEA/csv/150/EMEA.en.jsonl...\n",
      "Filtering sentences that are >= 150 tokens to ./datasets/EMEA/csv/150/EMEA.en.jsonl...\n",
      "2024-06-11 13:30:20,236 - INFO - Concatening remaining sentences to ./datasets/EMEA/csv/150/EMEA.en.jsonl\n",
      "Concatening remaining sentences to ./datasets/EMEA/csv/150/EMEA.en.jsonl\n",
      "2024-06-11 13:30:21,027 - INFO - Concatenated sentences in en to reach 21625 samples >= 150 tokens\n",
      "Concatenated sentences in en to reach 21625 samples >= 150 tokens\n",
      "2024-06-11 13:30:21,027 - INFO - Generating concatenated .txt version of original dataset for both languages...\n",
      "Generating concatenated .txt version of original dataset for both languages...\n",
      "2024-06-11 13:30:21,582 - INFO - ==== Data preprocessing complete ====\n",
      "==== Data preprocessing complete ====\n"
     ]
    }
   ],
   "source": [
    "!python preprocess2.py --config_file exp-configs/EMEA/config-125M-nl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:35:37,825 - INFO - Parsing arguments...\n",
      "Parsing arguments...\n",
      "2024-06-11 13:35:37,825 - INFO - Loading tokenizer...\n",
      "Loading tokenizer...\n",
      "2024-06-11 13:35:38,124 - INFO - ==== Sarting data processing script ====\n",
      "==== Sarting data processing script ====\n",
      "2024-06-11 13:35:38,124 - INFO - This may take a while depending on the size of the dataset...\n",
      "This may take a while depending on the size of the dataset...\n",
      "2024-06-11 13:35:38,124 - INFO - Counting tokens for en...\n",
      "Counting tokens for en...\n",
      "Generating byte offset dataset from file:  EMEA/150/EMEA-c.en\n",
      "2024-06-11 13:35:51,719 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA-c.en.csv: 21429\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA-c.en.csv: 21429\n",
      "2024-06-11 13:35:51,719 - INFO - Filtering sentences for en...\n",
      "Filtering sentences for en...\n",
      "2024-06-11 13:35:51,779 - INFO - Generating JSONL for en...\n",
      "Generating JSONL for en...\n",
      "2024-06-11 13:35:52,262 - INFO - Counting tokens for nl...\n",
      "Counting tokens for nl...\n",
      "Generating byte offset dataset from file:  EMEA/150/EMEA-c.nl\n",
      "2024-06-11 13:36:11,964 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA-c.nl.csv: 42704\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA-c.nl.csv: 42704\n",
      "2024-06-11 13:36:11,964 - INFO - Filtering sentences for nl...\n",
      "Filtering sentences for nl...\n",
      "2024-06-11 13:36:12,038 - INFO - Generating JSONL for nl...\n",
      "Generating JSONL for nl...\n",
      "Number of exids in file 1: %s 21429\n",
      "Number of exids in file 2: %s 42704\n",
      "Number of common exids found %s 21083\n",
      "2024-06-11 13:36:12,629 - INFO - Common exids have been written to ./datasets/EMEA/csv/150/common_exids-150.csv\n",
      "Common exids have been written to ./datasets/EMEA/csv/150/common_exids-150.csv\n",
      "2024-06-11 13:36:12,631 - INFO - 21083 common example IDs found\n",
      "21083 common example IDs found\n",
      "Truncating sentences in file:  EMEA/150/EMEA-c.en.jsonl  to  150  tokens\n",
      "Truncated  21083  sentences to  EMEA/150/EMEA-c-150.en.jsonl\n",
      "Done!\n",
      "Truncating sentences in file:  EMEA/150/EMEA-c.nl.jsonl  to  150  tokens\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Truncated  21083  sentences to  EMEA/150/EMEA-c-150.nl.jsonl\n",
      "Done!\n",
      "2024-06-11 13:36:49,974 - INFO - ==== Data processing script completed ====\n",
      "==== Data processing script completed ====\n"
     ]
    }
   ],
   "source": [
    "# change dataset name to name + \"-c\" in running this right after preprocessing!!!\n",
    "!python process_data.py --config_file exp-configs/EMEA/config-125M-nl.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
