{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-10 14:06:16,642 - INFO - Parsing arguments...\n",
      "Parsing arguments...\n",
      "2024-06-10 14:06:16,642 - INFO - Loading tokenizer...\n",
      "Loading tokenizer...\n",
      "2024-06-10 14:06:17,006 - INFO - ==== Starting data preprocessing script ====\n",
      "==== Starting data preprocessing script ====\n",
      "2024-06-10 14:06:17,006 - INFO - This may take a while depending on the size of the dataset...\n",
      "This may take a while depending on the size of the dataset...\n",
      "2024-06-10 14:06:17,006 - INFO - Counting tokens for en...\n",
      "Counting tokens for en...\n",
      "Generating byte offset dataset from file:  EMEA/EMEA.en\n",
      "2024-06-10 14:06:36,114 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.en.csv: 840\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.en.csv: 840\n",
      "2024-06-10 14:06:36,115 - INFO - Counting tokens for nl...\n",
      "Counting tokens for nl...\n",
      "Generating byte offset dataset from file:  EMEA/EMEA.nl\n",
      "2024-06-10 14:07:02,415 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.nl.csv: 3910\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.nl.csv: 3910\n",
      "2024-06-10 14:07:02,415 - INFO - Filtering sentences that are >= 150 tokens to ./datasets/EMEA/csv/150/EMEA.en.jsonl...\n",
      "Filtering sentences that are >= 150 tokens to ./datasets/EMEA/csv/150/EMEA.en.jsonl...\n",
      "2024-06-10 14:07:02,566 - INFO - Concatening remaining sentences to ./datasets/EMEA/csv/150/EMEA.en.jsonl\n",
      "Concatening remaining sentences to ./datasets/EMEA/csv/150/EMEA.en.jsonl\n",
      "2024-06-10 14:07:03,523 - INFO - Concatenated sentences in en to reach 9605 samples >= 150 tokens\n",
      "Concatenated sentences in en to reach 9605 samples >= 150 tokens\n",
      "2024-06-10 14:07:03,523 - INFO - Generating concatenated .txt version of original dataset for both languages...\n",
      "Generating concatenated .txt version of original dataset for both languages...\n",
      "2024-06-10 14:07:04,139 - INFO - ==== Data preprocessing complete ====\n",
      "==== Data preprocessing complete ====\n"
     ]
    }
   ],
   "source": [
    "!python preprocess2.py --config_file exp-configs/EMEA/config-125M-nl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-10 12:47:15,808 - INFO - Parsing arguments...\n",
      "Parsing arguments...\n",
      "2024-06-10 12:47:15,809 - INFO - Loading tokenizer...\n",
      "Loading tokenizer...\n",
      "2024-06-10 12:47:16,097 - INFO - ==== Sarting data processing script ====\n",
      "==== Sarting data processing script ====\n",
      "2024-06-10 12:47:16,097 - INFO - This may take a while depending on the size of the dataset...\n",
      "This may take a while depending on the size of the dataset...\n",
      "2024-06-10 12:47:16,097 - INFO - Counting tokens for en...\n",
      "Counting tokens for en...\n",
      "Generating byte offset dataset from file:  EMEA/EMEA.en\n",
      "2024-06-10 12:47:35,185 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.en.csv: 840\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.en.csv: 840\n",
      "2024-06-10 12:47:35,185 - INFO - Filtering sentences for en...\n",
      "Filtering sentences for en...\n",
      "2024-06-10 12:47:35,451 - INFO - Generating JSONL for en...\n",
      "Generating JSONL for en...\n",
      "2024-06-10 12:47:37,412 - INFO - Counting tokens for nl...\n",
      "Counting tokens for nl...\n",
      "Generating byte offset dataset from file:  EMEA/EMEA.nl\n",
      "2024-06-10 12:48:04,100 - INFO - Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.nl.csv: 3910\n",
      "Number of samples >= 150 tokens in ./datasets/EMEA/csv/150/EMEA.nl.csv: 3910\n",
      "2024-06-10 12:48:04,100 - INFO - Filtering sentences for nl...\n",
      "Filtering sentences for nl...\n",
      "2024-06-10 12:48:04,370 - INFO - Generating JSONL for nl...\n",
      "Generating JSONL for nl...\n",
      "Number of exids in file 1: %s 840\n",
      "Number of exids in file 2: %s 3910\n",
      "Number of common exids found %s 681\n",
      "2024-06-10 12:48:06,402 - INFO - Common exids have been written to ./datasets/EMEA/csv/150/common_exids-150.csv\n",
      "Common exids have been written to ./datasets/EMEA/csv/150/common_exids-150.csv\n",
      "2024-06-10 12:48:06,402 - INFO - 681 common example IDs found\n",
      "681 common example IDs found\n",
      "Truncating sentences in file:  EMEA/EMEA.en.jsonl  to  150  tokens\n",
      "Truncated  681  sentences to  EMEA/150/EMEA-150.en.jsonl\n",
      "Done!\n",
      "Truncating sentences in file:  EMEA/EMEA.nl.jsonl  to  150  tokens\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Truncated  681  sentences to  EMEA/150/EMEA-150.nl.jsonl\n",
      "Done!\n",
      "2024-06-10 12:48:11,899 - INFO - ==== Data processing script completed ====\n",
      "==== Data processing script completed ====\n"
     ]
    }
   ],
   "source": [
    "!python process_data.py --config_file exp-configs/EMEA/config-125M-nl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_lib import filter_large_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_large_entries(\"datasets/EMEA/csv/150/EMEA.en.csv\", \"datasets/EMEA/csv/150/EMEA.en.jsonl\", 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
